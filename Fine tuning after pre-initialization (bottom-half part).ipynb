{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "If using this code, please cite our work using :\n",
    "\n",
    "Susan, Seba, and Jatin Malhotra. \"CNN Pre-Initialization by Minimalistic Part-Learning for Handwritten Numeral Recognition.\" In International Conference on Mining Intelligence and Knowledge Exploration. Springer, Cham, 2019.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5% Training for pre-initalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3000, 28, 28, 1)\n",
      "3000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From c:\\users\\jatin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\jatin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\jatin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 1.9851 - acc: 0.2863 - val_loss: 1.3724 - val_acc: 0.5164\n",
      "Epoch 2/12\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 1.2627 - acc: 0.5513 - val_loss: 1.0698 - val_acc: 0.6084\n",
      "Epoch 3/12\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.9176 - acc: 0.6687 - val_loss: 0.7453 - val_acc: 0.7073\n",
      "Epoch 4/12\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.7393 - acc: 0.7340 - val_loss: 0.7526 - val_acc: 0.7160\n",
      "Epoch 5/12\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.6536 - acc: 0.7657 - val_loss: 0.5765 - val_acc: 0.7760\n",
      "Epoch 6/12\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.6014 - acc: 0.7727 - val_loss: 0.6418 - val_acc: 0.7441\n",
      "Epoch 7/12\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.5807 - acc: 0.7823 - val_loss: 0.5139 - val_acc: 0.7951\n",
      "Epoch 8/12\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.5257 - acc: 0.8043 - val_loss: 0.5594 - val_acc: 0.7763\n",
      "Epoch 9/12\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.4993 - acc: 0.8153 - val_loss: 0.5321 - val_acc: 0.7888\n",
      "Epoch 10/12\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.4637 - acc: 0.8287 - val_loss: 0.6256 - val_acc: 0.7644\n",
      "Epoch 11/12\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.4604 - acc: 0.8260 - val_loss: 0.4885 - val_acc: 0.8049\n",
      "Epoch 12/12\n",
      "3000/3000 [==============================] - 4s 1ms/step - loss: 0.4386 - acc: 0.8387 - val_loss: 0.5206 - val_acc: 0.7951\n",
      "Test loss: 0.5206226079463959\n",
      "Test accuracy: 0.7951\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train_top = np.load('x_3000_bottomview.npy')\n",
    "y_train_top = np.load('3000_y.npy')\n",
    "\n",
    "x_train = x_train_top\n",
    "y_train = y_train_top\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bottomView.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 95% for fining tune on top of pre-initailized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('bottomView.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (57000, 28, 28, 1)\n",
      "57000 train samples\n",
      "10000 test samples\n",
      "Train on 57000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "57000/57000 [==============================] - 38s 666us/step - loss: 0.1639 - acc: 0.9504 - val_loss: 0.0553 - val_acc: 0.9829\n",
      "Epoch 2/12\n",
      "57000/57000 [==============================] - 37s 646us/step - loss: 0.0819 - acc: 0.9749 - val_loss: 0.0338 - val_acc: 0.9887\n",
      "Epoch 3/12\n",
      "57000/57000 [==============================] - 37s 654us/step - loss: 0.0640 - acc: 0.9814 - val_loss: 0.0367 - val_acc: 0.9878\n",
      "Epoch 4/12\n",
      "57000/57000 [==============================] - 38s 669us/step - loss: 0.0505 - acc: 0.9845 - val_loss: 0.0273 - val_acc: 0.9916\n",
      "Epoch 5/12\n",
      "57000/57000 [==============================] - 42s 731us/step - loss: 0.0450 - acc: 0.9869 - val_loss: 0.0204 - val_acc: 0.9939\n",
      "Epoch 6/12\n",
      "57000/57000 [==============================] - 46s 811us/step - loss: 0.0394 - acc: 0.9879 - val_loss: 0.0258 - val_acc: 0.9928\n",
      "Epoch 7/12\n",
      "57000/57000 [==============================] - 46s 811us/step - loss: 0.0355 - acc: 0.9890 - val_loss: 0.0207 - val_acc: 0.9930\n",
      "Epoch 8/12\n",
      "57000/57000 [==============================] - 47s 824us/step - loss: 0.0319 - acc: 0.9901 - val_loss: 0.0248 - val_acc: 0.9918\n",
      "Epoch 9/12\n",
      "57000/57000 [==============================] - 57s 1ms/step - loss: 0.0295 - acc: 0.9909 - val_loss: 0.0196 - val_acc: 0.9944\n",
      "Epoch 10/12\n",
      "57000/57000 [==============================] - 70s 1ms/step - loss: 0.0291 - acc: 0.9910 - val_loss: 0.0179 - val_acc: 0.9946\n",
      "Epoch 11/12\n",
      "57000/57000 [==============================] - 42s 736us/step - loss: 0.0262 - acc: 0.9922 - val_loss: 0.0180 - val_acc: 0.9945\n",
      "Epoch 12/12\n",
      "57000/57000 [==============================] - 72s 1ms/step - loss: 0.0253 - acc: 0.9923 - val_loss: 0.0170 - val_acc: 0.9948\n",
      "Test loss: 0.01698725189248007\n",
      "Test accuracy: 0.9948\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = np.load('57000_x.npy')\n",
    "y_train = np.load('57000_y.npy')\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = load_model('bottomView.h5')\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('bottomview_pred.npy',pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
